{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La Mobilière Insurance Data - Features aggregation\n",
    "Last modified by AB\n",
    "on the 12/06/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the data aggregation of La Mobilière customers data at two geographical levels: municipalities and postal areas (ZIP codes).\n",
    "The dataset at municipality levels only contains the 2095 municipalities whose administrative boundaries have not changed over the period. It also include information from the census (here processed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setFont(ax, font, size):\n",
    "    for label in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        label.set_fontname(font)\n",
    "        label.set_fontsize(size)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dictionary for type of building \n",
    "build_type_dic={'Einfamilienhaus': 'DH',\n",
    "       'Wohn- und Geschäftsgebäude': 'RCB',\n",
    "       'Mehrfamilienhaus bis 3 Wohnungen': 'M3less',\n",
    "       'Mehrfamilienhaus über 3 Wohnungen': 'M3',\n",
    "       'Eigentumswohnung': 'Cond',\n",
    "       'Heim, Spital, Anstalt': 'HHI',\n",
    "       'Landwirtschaftliches Gebäude': 'AB',\n",
    "       'Spezialgebäude':'SB',\n",
    "       'Geschäftsgebäude': 'CB',\n",
    "       'Parkhaus, Einstellhalle': 'P',\n",
    "       'Schule, Bildungsgebäude': 'School',\n",
    "       'Vereins-, Sport- und Freizeithaus': 'Sport',\n",
    "       'Schloss': 'Manor',\n",
    "       'Gebäude der öffentlichen Hand': 'Public',\n",
    "       'Kirche, Kloster': 'RB'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape of public data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../Data/publicData/original/2012.xls',\n",
       "       '../Data/publicData/original/2013.xls',\n",
       "       '../Data/publicData/original/2014.xls',\n",
       "       '../Data/publicData/original/2015.xls',\n",
       "       '../Data/publicData/original/2016.xls',\n",
       "       '../Data/publicData/original/2017.xls',\n",
       "       '../Data/publicData/original/2018.xlsx',\n",
       "       '../Data/publicData/original/2019.xlsx',\n",
       "       '../Data/publicData/original/2020.xlsx'], dtype='<U37')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../Data/publicData/original/\"\n",
    "files = sorted(list(glob.glob(path+'*')))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2010, 2019, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(files):\n",
    "    try:\n",
    "        df = pd.read_excel(j,index_col=None, header=None) \n",
    "    except:\n",
    "        df = pd.read_excel(j,index_col=None, header=None, engine='openpyxl') \n",
    "    df = df[ (df.index>8)]\n",
    "    df = df.dropna()\n",
    "    if i <= 2:\n",
    "        df.rename(columns = {0:'BFS', 1:'Municipality', 2:'Residents', 3:'Population density', \n",
    "                                 7:'Foreigners (%)', 8: 'Age [0-19]', 9:'Age [20-64]', 10:'Age [64+]'}, inplace = True)\n",
    "    else:\n",
    "        df.rename(columns = {0:'BFS', 1:'Municipality', 2:'Residents', 3:'Population density', \n",
    "                                 5:'Foreigners (%)', 6: 'Age [0-19]', 7:'Age [20-64]', 8:'Age [64+]'},inplace = True)      \n",
    "    df = df[['BFS', 'Municipality', 'Residents', 'Population density', 'Foreigners (%)', \n",
    "                 'Age [0-19]', 'Age [20-64]', 'Age [64+]']].reset_index(drop=True)\n",
    "    string = 'censusData_%d.csv'%years[i]\n",
    "    df.to_csv('../Data/publicData/'+string, index=None, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only data for those municipalities whose administrative boundaries have not changed over time\n",
    "### First generate list of municipalities that have not changed over time (which appear both in Census 2010 and 2018)\n",
    "## Historical ZIP to BFS mapping\n",
    "zip_bfs_folders_dict={2008:'20101101',2009:'20101101',2010:'20101101', \n",
    "                      2011:'20111101', 2012:'20121101',2013:'20131101',\n",
    "                      2014:'20141201',2015:'20151201',2016:'20161201',\n",
    "                      2017:'20171201',2018:'20181201',2018:'20181201',2019:'20191201'}\n",
    "zip_bfs_sep_dict={2008:';',2009:';',2010:';', \n",
    "                      2011:'\\t', 2012:'\\t',2013:'\\t',\n",
    "                      2014:'\\t',2015:'\\t',2016:'\\t',\n",
    "                      2017:';',2018:';',2018:';',2019:';'}\n",
    "\n",
    "## Zip codes - commune codes (year specific)\n",
    "zipBFS_2010 = pd.read_csv(\"../Data/ZIP_BFS_Historical_Mapping/\"+zip_bfs_folders_dict[2010]+\"/PLZO_CSV_WGS84.csv\",encoding='iso-8859-1', sep=zip_bfs_sep_dict[2010])\n",
    "zipBFS_2010.drop_duplicates(subset='BFS-Nr', inplace=True)\n",
    "\n",
    "## Zip codes - commune codes (year specific)\n",
    "zipBFS_2019 = pd.read_csv(\"../Data/ZIP_BFS_Historical_Mapping/\"+zip_bfs_folders_dict[2019]+\"/PLZO_CSV_WGS84.csv\",encoding='iso-8859-1', sep=zip_bfs_sep_dict[2019])\n",
    "zipBFS_2019.drop_duplicates(subset='BFS-Nr', inplace=True)\n",
    "\n",
    "merge=zipBFS_2010.merge(zipBFS_2019, on=['BFS-Nr'], how='inner')\n",
    "unchanged_mun=merge[['BFS-Nr']].copy()\n",
    "unchanged_mun.rename(columns={'BFS-Nr':'BFS'}, inplace=True)\n",
    "\n",
    "#Check with census data t be sure that the municipality exists in the census in all years otherwise remove from the list of unchanged municipalities\n",
    "for i in range(2010, 2019, 1):\n",
    "    string = 'censusData_%d.csv'%i\n",
    "    tmp=pd.read_csv('../Data/publicData/'+string,  encoding = 'utf-8')\n",
    "    unchanged_mun=unchanged_mun.merge(tmp['BFS'], on=['BFS'], how='inner')\n",
    "\n",
    "#Finally filter public data to keep only 'unchanged municipalities'\n",
    "for year in years:\n",
    "    string = 'censusData_%d.csv'%year\n",
    "    df=pd.read_csv('../Data/publicData/'+string,  encoding = 'utf-8')\n",
    "    df=df.merge(unchanged_mun, on=['BFS'], how='inner')\n",
    "    df.to_csv('../Data/publicData/'+string, index=None, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load municipalities Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Historical ZIP to BFS mapping\n",
    "zip_bfs_folders_dict={2008:'20101101',2009:'20101101',2010:'20101101', \n",
    "                      2011:'20111101', 2012:'20121101',2013:'20131101',\n",
    "                      2014:'20141201',2015:'20151201',2016:'20161201',\n",
    "                      2017:'20171201',2018:'20181201',2018:'20181201',2019:'20191201'}\n",
    "zip_bfs_sep_dict={2008:';',2009:';',2010:';', \n",
    "                      2011:'\\t', 2012:'\\t',2013:'\\t',\n",
    "                      2014:'\\t',2015:'\\t',2016:'\\t',\n",
    "                      2017:';',2018:';',2018:';',2019:';'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(df, col1,col2, feat):\n",
    "\n",
    "    tmp = df.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp = tmp.drop_duplicates()  ## Drop duplicates to keep only one record per person\n",
    "    tmp[feat] = 1\n",
    "    tmp = tmp.groupby([col2]).count()\n",
    "    tmp[feat] =  tmp\n",
    "    tmp[feat] = tmp[feat].fillna(0)\n",
    "    tmp = tmp.filter([feat], axis=1)\n",
    "    return tmp\n",
    "\n",
    "def fraction(df, col1, col2, feat,specicvalue):\n",
    "\n",
    "    tmp = df.filter([col1,col2], axis=1)\n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp = tmp.groupby([col2]).count()\n",
    "\n",
    "    tmp0 = df.filter([col1,col2], axis=1)\n",
    "    tmp0 = tmp0[tmp0[col1]==specicvalue]\n",
    "    tmp0 = tmp0.groupby([col2]).count()\n",
    "    tmp  = pd.merge(tmp,tmp0,on=col2,how='left')\n",
    "    a = col1+'_x'\n",
    "    b = col1+'_y'\n",
    "    tmp[feat] = tmp[b]/tmp[a]\n",
    "    tmp[feat] = tmp[feat].fillna(0)\n",
    "    tmp = tmp.filter([feat], axis=1)\n",
    "    return tmp\n",
    "\n",
    "def conf_int_mean(df, col1, col2, feat):\n",
    "    p = 0.5\n",
    "    tmp = df.filter([col1, col2, 'Nmbr'], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    mean = tmp.groupby(col2)[col1].mean()\n",
    "    std = tmp.groupby(col2)[col1].std()\n",
    "    count = tmp.groupby(col2)[col1].count()\n",
    "    count_sqrt=count.apply(lambda x: sqrt(x))\n",
    "    d={'mean':mean, 'std':std, 'size':count_sqrt }\n",
    "    df=pd.DataFrame(d)\n",
    "    df['std']=df.apply(lambda x: 0 if x['size']==1 else x['std'], axis=1)\n",
    "    tmp=df.apply(lambda x: [x['mean']-1.96*x['std']/x['size'], x['mean']+1.96*x['std']/x['size']], axis=1)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    return tmp\n",
    "    \n",
    "\n",
    "def percentile(df, col1, col2, feat, p):\n",
    "    tmp = df.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(p)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2008, 2020, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EPFL-Dataset_01-01-2008.csv', 'EPFL-Dataset_01-01-2009.csv',\n",
       "       'EPFL-Dataset_01-01-2010.csv', 'EPFL-Dataset_01-01-2011.csv',\n",
       "       'EPFL-Dataset_01-01-2012.csv', 'EPFL-Dataset_01-01-2013.csv',\n",
       "       'EPFL-Dataset_01-01-2014.csv', 'EPFL-Dataset_01-01-2015.csv',\n",
       "       'EPFL-Dataset_01-01-2016.csv', 'EPFL-Dataset_01-01-2017.csv',\n",
       "       'EPFL-Dataset_01-01-2018.csv', 'EPFL-Dataset_01-01-2019.csv'],\n",
       "      dtype='<U27')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Folder\n",
    "current = os.getcwd()\n",
    "path = \"../Data/historicalData/\"\n",
    "os.chdir(path)\n",
    "result = sorted(list((glob.glob('*.csv'))))\n",
    "os.chdir(current)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "usr = []\n",
    "zips = []\n",
    "for i,j in enumerate(result):\n",
    "    df = pd.read_csv(path+j, error_bad_lines=False, encoding='iso-8859-1', sep=\";\")\n",
    "    usr.append(df['Nmbr'].nunique())\n",
    "    print(years[i])\n",
    "    ## Zip codes - commune codes (year specific)\n",
    "    zipBFS = pd.read_csv(\"../Data/ZIP_BFS_Historical_Mapping/\"+zip_bfs_folders_dict[years[i]]+\"/PLZO_CSV_WGS84.csv\",encoding='iso-8859-1', sep=zip_bfs_sep_dict[years[i]])\n",
    "    zipBFS.rename(columns={'PLZ':'ZIP', 'BFS-Nr':'BFS'}, inplace=True)\n",
    "    zipBFS = zipBFS[['ZIP', 'BFS']]\n",
    "    zipBFS = zipBFS.drop_duplicates(subset=['ZIP', 'BFS'], keep='first').reset_index(drop=True)\n",
    "    insDataRed = pd.merge(df, zipBFS, on = 'ZIP')\n",
    "    \n",
    "    ##### 1. Unemployment rate\n",
    "    col1 = 'JobState'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    specicvalue = 'Arbeitslos   '\n",
    "    feat = 'unemp'\n",
    "    tmp = fraction(insDataRed, col1, col2, feat,specicvalue)\n",
    "    dfFeat = tmp.filter([feat],axis=1)\n",
    "\n",
    "    ## 2. Average age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'age_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 3. Confidence interval for the mean of age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'age_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 4. Std age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'age_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 5. 05 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'age_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 6. 25 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'age_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 7. 50 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'age_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 8. 75 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'age_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 9. 95 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'age_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 10. Fraction of owners\n",
    "    col1 = 'Own/Rent'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    specicvalue = 'E'  \n",
    "    feat = 'frac_own'\n",
    "    tmp = fraction(insDataRed, col1, col2, feat,specicvalue)\n",
    "    tmp = tmp.filter([feat],axis=1)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 11. Fraction of foreigners\n",
    "    col1 = 'Nation'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp['swiss'] = np.where(tmp['Nation']=='CH ', 'yes', 'no') ## count if swiss or not\n",
    "    col1='swiss'\n",
    "    specicvalue = 'no'\n",
    "    feat = 'frac_foreign'\n",
    "    tmp = fraction(tmp, col1, col2, feat, specicvalue)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 12. Average number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'child_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 13. Confidence Interval for the mean number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'child_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 14. Std number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'child_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 15. 5 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'child_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 16. 25 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'child_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 17. 50 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'child_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.5)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 18. 75 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'child_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 19. 95 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'child_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 20. Number of customers\n",
    "    cust = insDataRed.filter(['Nmbr','BFS'], axis=1).drop_duplicates()\n",
    "    cust = cust.groupby(['BFS']).count()\n",
    "    #tmp = swissData.filter(['Population', 'BFS'], axis=1)\n",
    "    #cust = pd.merge(cust,tmp,on='BFS')\n",
    "    #cust['f6'] = cust['Nmbr']/cust['Population']\n",
    "    cust['custom'] = cust['Nmbr']\n",
    "    cust = cust.filter(['BFS','custom'],axis=1)\n",
    "    dfFeat = pd.merge(dfFeat, cust, on = 'BFS')\n",
    "\n",
    "    ## 21. Fraction of women\n",
    "    col1 = 'Gender'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp['women'] =  np.where(tmp[col1]=='W ', 'yes', 'no') ## count if swiss or not\n",
    "    feat = 'frac_women'\n",
    "    specicvalue = 'no'\n",
    "    tmp0 = tmp.groupby(['BFS']).count()\n",
    "\n",
    "    tmp = tmp[tmp[col1]==\"W\"]\n",
    "    tmp = tmp.groupby(['BFS']).count()\n",
    "    tmp[feat]=tmp['Gender']/tmp0['Gender']\n",
    "    tmp = tmp.filter([feat],axis=1)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 11. Fraction of customers who insured at least one car\n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp['insured_car'] = np.where(tmp['Car_Premium']!=0, 'yes', 'no') ## count if swiss or not\n",
    "    col1='insured_car'\n",
    "    specicvalue = 'yes'\n",
    "    feat = 'car1_custom_frac'\n",
    "    tmp = fraction(tmp, col1, col2, feat, specicvalue)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 22. Class of the car (PROPORTION PER CLASS)\n",
    "    col1 = 'Car1_Class'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    for k in list(tmp[col1].unique()):\n",
    "        t='car1_'+k+'_frac'\n",
    "        tmp[t]=0\n",
    "        tmp[t]=tmp.apply(lambda x: 1 if x[col1]==k else 0, axis=1)\n",
    "    tmp=tmp.groupby(col2).mean() \n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 23. Average Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_pr_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).mean()\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 24. Confidence Interval for the mean Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_pr_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 25. Std Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_pr_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).std()\n",
    "    tmp.columns = [feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 26. 05 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.05)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 27. 25 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.25)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 28. 50 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.5)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 29. 75 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.75)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 30. 95 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.95)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "\n",
    "    ## 32. 05 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct05'\n",
    "    p = 0.05\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 33. 25 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct25'\n",
    "    p = 0.25\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 34. 50 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct50'\n",
    "    p = 0.50\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 35. 75 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct75'\n",
    "    p = 0.75\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 36. 95 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct95'\n",
    "    p = 0.95\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 37. Avg CCM of the car\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).mean()\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 24. Confidence Interval for the mean CCM of the car\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 25. Std CCM of the car\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).std()\n",
    "    tmp.columns = [feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 38. 05 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct05'\n",
    "    p = 0.05\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 39. 25 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct25'\n",
    "    p = 0.25\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 40. 50 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct50'\n",
    "    p = 0.50\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 41. 75 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct75'\n",
    "    p = 0.75\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 42. 95 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct95'\n",
    "    p = 0.95\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 43. Average number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_claim_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).mean()\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 44. Confidence interval number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_claim_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 45. Std number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_claim_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).std()\n",
    "    tmp.columns = [feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 46. 05 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct05'\n",
    "    p = 0.05\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 47. 25 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct25'\n",
    "    p = 0.25\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    \n",
    "    ## 48. 50 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct50'\n",
    "    p = 0.50\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    \n",
    "    ## 49. 75 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct75'\n",
    "    p = 0.75\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 50. 95 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct95'\n",
    "    p = 0.95\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 51. Average sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 52. Confidence Interval for the mean of the sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 53. Std sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 54. 05 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 55. 25 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 56. 50 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 57. 75 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 58. 95 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 59. Average sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_prem_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 60. Confidence Interval for the mean of the sum of claims of the car\n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_prem_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 61. Std sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_prem_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 62. 05 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 63. 25 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 64. 50 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 65. 75 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 66. 95 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 11. Fraction of customers who insured at least one building\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp['insured_building'] = np.where(tmp['HH_and_Bld_Prem.']!=0, 'yes', 'no') ## count if swiss or not\n",
    "    col1='insured_building'\n",
    "    specicvalue = 'yes'\n",
    "    feat = 'build_custom_frac'\n",
    "    tmp = fraction(tmp, col1, col2, feat, specicvalue)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 68. 05 pct class of furniture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.05)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 69. 25 pct class of furniture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.25)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "\n",
    "    ## 70. 50 pct class of furniture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.50)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 71. 75 pct class of furniture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.75)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 72. 95 pct class of furniture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.95)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 73. Average Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'rooms_mean'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 74. Confidence interval for the mean of Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'rooms_ci95'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 75. Std Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'rooms_std'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 76. 05 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'rooms_pct05'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 77. 25 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'rooms_pct25'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 78. 50 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'rooms_pct50'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 79. 75 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'rooms_pct75'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 80. 95 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'rooms_pct95'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 81. Average Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_ins_mean'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 82. Confidence interval for the mean of Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_ins_ci95'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 83. Std Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_ins_std'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 84. 05 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct05'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 85. 25 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct25'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 86. 50 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct50'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 87. 75 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct75'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 88. 95 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct95'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 90. 05 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_y_pct05'\n",
    "    p = 0.05\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 91. 25 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_y_pct25'\n",
    "    p = 0.25\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "    ## 92. 50 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_y_pct50'\n",
    "    p = 0.50\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 93. 75 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_y_pct75'\n",
    "    p = 0.75\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 94. 95 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_y_pct95'\n",
    "    p = 0.95\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "\n",
    "    ## 95. Type of building (proportion per type)\n",
    "    col1 = 'Type'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp[col1]=tmp.apply(lambda x: x[col1].strip(), axis=1)\n",
    "    tmp = tmp[tmp[col1]!= '']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1]=tmp.apply(lambda x: build_type_dic[x[col1]], axis=1)\n",
    "    for k in list(tmp[col1].unique()):\n",
    "        t='build_'+k+'_frac'\n",
    "        tmp[t]=0\n",
    "        tmp[t]=tmp.apply(lambda x: 1 if x[col1]==k else 0, axis=1)\n",
    "    tmp=tmp.groupby(col2).mean()  \n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "\n",
    "\n",
    "    ## 96. Avg number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_claim_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 97. Confidence Interval mean number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_claim_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 98. Std number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_claim_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 99. 05 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 100. 25 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 101. 50 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')    \n",
    "    \n",
    "    ## 102. 75 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')    \n",
    "    \n",
    "    ## 103. 95 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')      \n",
    "    \n",
    "    ## 104. Avg. sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    ## 105. Confidence Interval mean number of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 106. Std sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')\n",
    "    \n",
    "    ## 107. 05 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    ## 108. 25 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    ## 109. 50 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    ## 110. 75 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')  \n",
    "    \n",
    "    ## 111. 95 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')    \n",
    "\n",
    "    ## 112. Average Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_prem_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    ## 113. Confidence interval for the mean of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_prem_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS')  \n",
    "    \n",
    "    ## 114. Std of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_prem_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "\n",
    "    ## 115. 05 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    ## 116. 25 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    ## 117. 50 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    ## 118. 75 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    ## 119. 95 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'BFS'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'BFS') \n",
    "    \n",
    "    \n",
    "    for j in build_type_dic.values():\n",
    "        a='build_'+j+'_frac'\n",
    "        if a not in dfFeat.columns:\n",
    "            dfFeat[a]=0\n",
    "            \n",
    "    for j in [ 'MKL', 'KWA','VAN', 'OMK', 'UMK', 'MIC', 'CPE', 'SUV', 'LKL', 'CAB', 'ATV', 'SMA', 'ROL', 'CHO', 'GMA'] :\n",
    "        a='car1_'+j+'_frac'\n",
    "        if a not in dfFeat.columns:\n",
    "            dfFeat[a]=0\n",
    "\n",
    "    dfFeat.reset_index()\n",
    "    dfFeat.to_csv(\"../Data/aggregatedData/features_%d.csv\"%years[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Census data at municipality level. Keep only municipalities whose boundaries have not changed overtime. \n",
    "\n",
    "#First identify 2093 'unchanged' municipalities. \n",
    "#Keep only data for those municipalities whose administrative boundaries have not changed over time\n",
    "### First generate list of municipalities that have not changed over time (which appear both in Census 2010 and 2019)\n",
    "## Historical ZIP to BFS mapping\n",
    "zip_bfs_folders_dict={2008:'20101101',2009:'20101101',2010:'20101101', \n",
    "                      2011:'20111101',2012:'20121101',2013:'20131101',\n",
    "                      2014:'20141201',2015:'20151201',2016:'20161201',\n",
    "                      2017:'20171201',2018:'20181201',2019:'20191201'}\n",
    "zip_bfs_sep_dict={2008:';',2009:';',2010:';', \n",
    "                  2011:'\\t',2012:'\\t',2013:'\\t',\n",
    "                  2014:'\\t',2015:'\\t',2016:'\\t',\n",
    "                  2017:';',2018:';',2019:';'}\n",
    "\n",
    "## Zip codes - commune codes (year specific)\n",
    "zipBFS_2010 = pd.read_csv(\"../Data/ZIP_BFS_Historical_Mapping/\"+zip_bfs_folders_dict[2010]+\"/PLZO_CSV_WGS84.csv\",encoding='iso-8859-1', sep=zip_bfs_sep_dict[2010])\n",
    "zipBFS_2010.drop_duplicates(subset='BFS-Nr', inplace=True)\n",
    "\n",
    "## Zip codes - commune codes (year specific)\n",
    "zipBFS_2019 = pd.read_csv(\"../Data/ZIP_BFS_Historical_Mapping/\"+zip_bfs_folders_dict[2019]+\"/PLZO_CSV_WGS84.csv\",encoding='iso-8859-1', sep=zip_bfs_sep_dict[2019])\n",
    "zipBFS_2019.drop_duplicates(subset='BFS-Nr', inplace=True)\n",
    "\n",
    "merge=zipBFS_2010.merge(zipBFS_2019, on=['BFS-Nr'], how='inner')\n",
    "unchanged_mun=merge[['BFS-Nr']].copy()\n",
    "unchanged_mun.rename(columns={'BFS-Nr':'BFS'}, inplace=True)\n",
    "\n",
    "#Check with census data t be sure that the municipality exists in the census in all years otherwise remove from the list of unchanged municipalities\n",
    "for i in range(2010, 2019, 1):\n",
    "    string = 'censusData_%d.csv'%i\n",
    "    tmp=pd.read_csv('../Data/publicData/'+string,  encoding = 'utf-8')\n",
    "    unchanged_mun=unchanged_mun.merge(tmp['BFS'], on=['BFS'], how='inner')\n",
    "\n",
    "#Finally filter public data to keep only 'unchanged municipalities'\n",
    "for i in range(2010, 2019, 1):\n",
    "    string = 'censusData_%d.csv'%i\n",
    "    df=pd.read_csv('../Data/publicData/'+string,  encoding = 'utf-8')\n",
    "    df=df.merge(unchanged_mun, on=['BFS'], how='inner')\n",
    "    df.to_csv('../Data/publicData/'+string, index=None, encoding = 'utf-8')\n",
    "    \n",
    "#Second merge census info into municipality data\n",
    "for i in range(2010, 2019, 1):\n",
    "    dfAggregated = pd.read_csv('../Data/aggregatedData/features_%d.csv'%i)\n",
    "    dfCensus = pd.read_csv('../Data/publicData/censusData_%d.csv'%i)\n",
    "    tmp = pd.merge(dfAggregated, dfCensus, on = 'BFS', how='right')\n",
    "    #Rename census variables\n",
    "    tmp.rename(columns={'Municipality':'municipality', 'Residents':'pop_census', 'Population density':'pop_d_census',\n",
    "                       'Foreigners (%)': 'frac_foreign_census', 'Age [0-19]':'age_0_19_census', 'Age [20-64]':'age_20_64_census',\n",
    "                       'Age [64+]':'age_65+_census'}, inplace=True)\n",
    "    #if zero customers, set custom to 0 and replace all other to np.nan\n",
    "    dict_format={'custom': 'Int64', 'BFS':'Int64',  'pop_census':'Int64'}\n",
    "    \n",
    "    tmp['custom']=tmp['custom'].fillna(0)\n",
    "    tmp=tmp.fillna(np.nan)\n",
    "    \n",
    "    tmp=tmp.astype(dict_format, copy=True)\n",
    "    \n",
    "    tmp.to_csv('../Data/combinedData/municipality_combinedData_%d.csv'%i, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr = []\n",
    "zips = []\n",
    "for i,j in enumerate(result):\n",
    "    df = pd.read_csv(path+j, error_bad_lines=False, encoding='iso-8859-1', sep=\";\")\n",
    "    usr.append(df['Nmbr'].nunique())\n",
    "    print(years[i])\n",
    "    ## Zip codes - commune codes (year specific)\n",
    "    zipBFS = pd.read_csv(\"../Data/ZIP_BFS_Historical_Mapping/\"+zip_bfs_folders_dict[years[i]]+\"/PLZO_CSV_WGS84.csv\",encoding='iso-8859-1', sep=zip_bfs_sep_dict[years[i]])\n",
    "    zipBFS.rename(columns={'PLZ':'ZIP', 'BFS-Nr':'BFS'}, inplace=True)\n",
    "    zipBFS = zipBFS[['ZIP', 'BFS']]\n",
    "    zipBFS = zipBFS.drop_duplicates(subset=['ZIP', 'BFS'], keep='first').reset_index(drop=True)\n",
    "    insDataRed = pd.merge(df, zipBFS['ZIP'], on = 'ZIP') #To make sure we only keep 'valid' zip codes\n",
    "    \n",
    "     ##### 1. Unemployment rate\n",
    "    col1 = 'JobState'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    specicvalue = 'Arbeitslos   '\n",
    "    feat = 'unemp'\n",
    "    tmp = fraction(insDataRed, col1, col2, feat,specicvalue)\n",
    "    dfFeat = tmp.filter([feat],axis=1)\n",
    "\n",
    "    ## 2. Average age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'age_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 3. Confidence interval for the mean of age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'age_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 4. Std age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'age_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 5. 05 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'age_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 6. 25 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'age_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 7. 50 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'age_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.5)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 8. 75 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'age_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 9. 95 pct age\n",
    "    col1 = 'YearOfBirth'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'age_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp[col1] =tmp.apply(lambda x: np.nan if x[col1]==0 else x[col1], axis=1)    \n",
    "    tmp = tmp.dropna() ## remove if we don't have info\n",
    "    tmp[col1] =tmp.apply(lambda x: years[i] - x[col1], axis=1)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 10. Fraction of owners\n",
    "    col1 = 'Own/Rent'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    specicvalue = 'E'  \n",
    "    feat = 'frac_own'\n",
    "    tmp = fraction(insDataRed, col1, col2, feat,specicvalue)\n",
    "    tmp = tmp.filter([feat],axis=1)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 11. Fraction of foreigners\n",
    "    col1 = 'Nation'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp['swiss'] = np.where(tmp['Nation']=='CH ', 'yes', 'no') ## count if swiss or not\n",
    "    col1='swiss'\n",
    "    specicvalue = 'no'\n",
    "    feat = 'frac_foreign'\n",
    "    tmp = fraction(tmp, col1, col2, feat, specicvalue)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 12. Average number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'child_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 13. Confidence Interval for the mean number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'child_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 14. Std number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'child_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 15. 5 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'child_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 16. 25 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'child_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 17. 50 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'child_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.5)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 18. 75 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'child_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 19. 95 pct number of Children\n",
    "    col1 = 'Children_0-26'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'child_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 20. Number of customers\n",
    "    cust = insDataRed.filter(['Nmbr','ZIP'], axis=1)\n",
    "    cust = cust.groupby(['ZIP']).count()\n",
    "    #tmp = swissData.filter(['Population', 'BFS'], axis=1)\n",
    "    #cust = pd.merge(cust,tmp,on='BFS')\n",
    "    #cust['f6'] = cust['Nmbr']/cust['Population']\n",
    "    cust['custom'] = cust['Nmbr']\n",
    "    cust = cust.filter(['ZIP','custom'],axis=1)\n",
    "    dfFeat = pd.merge(dfFeat, cust, on = 'ZIP')\n",
    "\n",
    "    ## 21. Fraction of women\n",
    "    col1 = 'Gender'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp['women'] =  np.where(tmp[col1]=='W ', 'yes', 'no') ## count if swiss or not\n",
    "    feat = 'frac_women'\n",
    "    specicvalue = 'no'\n",
    "    tmp0 = tmp.groupby(['ZIP']).count()\n",
    "\n",
    "    tmp = tmp[tmp[col1]==\"W\"]\n",
    "    tmp = tmp.groupby(['ZIP']).count()\n",
    "    tmp[feat]=tmp['Gender']/tmp0['Gender']\n",
    "    tmp = tmp.filter([feat],axis=1)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 11. Fraction of customers who insured at least one car\n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp['insured_car'] = np.where(tmp['Car_Premium']!=0, 'yes', 'no') ## count if swiss or not\n",
    "    col1='insured_car'\n",
    "    specicvalue = 'yes'\n",
    "    feat = 'car1_custom_frac'\n",
    "    tmp = fraction(tmp, col1, col2, feat, specicvalue)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "\n",
    "    ## 22. Class of the car\n",
    "    col1 = 'Car1_Class'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    for k in list(tmp[col1].unique()):\n",
    "        t='car1_'+k+'_frac'\n",
    "        tmp[t]=0\n",
    "        tmp[t]=tmp.apply(lambda x: 1 if x[col1]==k else 0, axis=1)\n",
    "    tmp=tmp.groupby(col2).mean()  \n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 23. Average Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_pr_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).mean()\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 24. Confidence Interval for the mean Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_pr_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 25. Std Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_pr_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).std()\n",
    "    tmp.columns = [feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 26. 05 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.05)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 27. 25 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.25)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 28. 50 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.5)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 29. 75 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.75)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 30. 95 pct Price of the car\n",
    "    col1 = 'Car1_Price'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_pr_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).quantile(0.95)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 32. 05 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct05'\n",
    "    p = 0.05\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 33. 25 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct25'\n",
    "    p = 0.25\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 34. 50 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct50'\n",
    "    p = 0.50\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 35. 75 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct75'\n",
    "    p = 0.75\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 36. 95 Percentile year of the car\n",
    "    col1 = 'Car1_1Imtr'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_y_pct95'\n",
    "    p = 0.95\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 37. Avg CCM of the car\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).mean()\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 24. Confidence Interval for the mean Price of the car\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 25. Std Price of the car\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).std()\n",
    "    tmp.columns = [feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "\n",
    "    ## 38. 05 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct05'\n",
    "    p = 0.05\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 39. 25 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct25'\n",
    "    p = 0.25\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 40. 50 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct50'\n",
    "    p = 0.50\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 41. 75 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct75'\n",
    "    p = 0.75\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 42. 95 Percentile of CCM\n",
    "    col1 = 'Car1_ccm'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_ccm_pct95'\n",
    "    p = 0.95\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 43. Average number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_claim_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).mean()\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 44. Confidence interval number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_claim_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 45. Std number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_claim_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby([col2]).std()\n",
    "    tmp.columns = [feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 46. 05 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct05'\n",
    "    p = 0.05\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 47. 25 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct25'\n",
    "    p = 0.25\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    \n",
    "    ## 48. 50 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct50'\n",
    "    p = 0.50\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    \n",
    "    ## 49. 75 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct75'\n",
    "    p = 0.75\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 50. 95 percentile number of claims per car\n",
    "    col1 = 'Car1_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_claim_pct95'\n",
    "    p = 0.95\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 51. Average sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 52. Confidence Interval for the mean of the sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 53. Std sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 54. 05 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 55. 25 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 56. 50 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 57. 75 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 58. 95 pct sum of claims of the car\n",
    "    col1 = 'Car1_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_sumcl_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 59. Average sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_prem_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 60. Confidence Interval for the mean of the sum of claims of the car\n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_prem_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 61. Std sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_prem_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 62. 05 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 63. 25 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 64. 50 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 65. 75 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 66. 95 pct sum of class premium of the car \n",
    "    col1 = 'Car_Premium'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'car1_prem_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 11. Fraction of customers who insured at least one building\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp['insured_building'] = np.where(tmp['HH_and_Bld_Prem.']!=0, 'yes', 'no') ## count if swiss or not\n",
    "    col1='insured_building'\n",
    "    specicvalue = 'yes'\n",
    "    feat = 'build_custom_frac'\n",
    "    tmp = fraction(tmp, col1, col2, feat, specicvalue)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = col2)\n",
    "    \n",
    "    ## 68. 05 pct class of forninture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.05)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 69. 25 pct class of forninture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.25)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "\n",
    "    ## 70. 50 pct class of forninture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.50)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 71. 75 pct class of forninture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.75)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 72. 95 pct class of forninture\n",
    "    col1 = 'Stand_of_furn'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'cl_furn_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]!= '   ']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1] = tmp[col1].astype('category')\n",
    "    cat_columns = tmp.select_dtypes(['category']).columns\n",
    "    tmp[cat_columns] = tmp[cat_columns].apply(lambda x: x.cat.codes) ## from categorical to number\n",
    "    tmp = tmp.groupby(col2)[col1].quantile(0.95)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 73. Average Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'rooms_mean'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 74. Confidence interval for the mean of Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'rooms_ci95'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 75. Std Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'rooms_std'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 76. 05 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'rooms_pct05'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 77. 25 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'rooms_pct25'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 78. 50 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'rooms_pct50'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 79. 75 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'rooms_pct75'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 80. 95 pct Number of Rooms\n",
    "    col1 = 'Rooms'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'rooms_pct95'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 81. Average Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_ins_mean'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 82. Confidence interval for the mean of Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_ins_ci95'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 83. Std Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_ins_std'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 84. 05 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct05'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 85. 25 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct25'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 86. 50 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct50'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 87. 75 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct75'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 88. 95 pct Building Insured Sum\n",
    "    col1 = 'Build_Ins_Sum'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_ins_pct95'\n",
    "    insDataRed[col1]=pd.to_numeric(insDataRed[col1],errors='coerce') ## transform into numeric\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "\n",
    "    ## 90. 05 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_y_pct05'\n",
    "    p = 0.05\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 91. 25 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_y_pct25'\n",
    "    p = 0.25\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 92. 50 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_y_pct50'\n",
    "    p = 0.50\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 93. 75 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'    ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_y_pct75'\n",
    "    p = 0.75\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 94. 95 Percentile Building Year of Constructions\n",
    "    col1 = 'Year_of_constr'    ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_y_pct95'\n",
    "    p = 0.95\n",
    "    tmp = percentile(insDataRed, col1, col2, feat, p)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "\n",
    "    ## 95. Average type of building\n",
    "    col1 = 'Type'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp[col1]=tmp.apply(lambda x: x[col1].strip(), axis=1)\n",
    "    tmp = tmp[tmp[col1]!= '']\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp[col1]=tmp.apply(lambda x: build_type_dic[x[col1]], axis=1)\n",
    "    for k in list(tmp[col1].unique()):\n",
    "        t='build_'+k+'_frac'\n",
    "        tmp[t]=0\n",
    "        tmp[t]=tmp.apply(lambda x: 1 if x[col1]==k else 0, axis=1)\n",
    "    tmp=tmp.groupby(col2).mean() \n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "        \n",
    "    ## 96. Avg number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_claim_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 97. Confidence Interval mean number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_claim_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 98. Std number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_claim_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 99. 05 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 100. 25 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 101. 50 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')    \n",
    "    \n",
    "    ## 102. 75 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')    \n",
    "    \n",
    "    ## 103. 95 pct number of claims per building\n",
    "    col1 = 'HHaB_ClaimsCt5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_claim_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')      \n",
    "    \n",
    "    ## 104. Avg. sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    ## 105. Confidence Interval mean sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns = [feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 106. Std sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')\n",
    "    \n",
    "    ## 107. 05 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    ## 108. 25 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    ## 109. 50 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    ## 110. 75 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')  \n",
    "    \n",
    "    ## 111. 95 pct sum of claims per building\n",
    "    col1 = 'HHaB_ClaimsSum5Y'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_sumcl_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')    \n",
    "\n",
    "    ## 112. Average Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_prem_mean'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).mean()\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    ## 113. Confidence interval for the mean of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_prem_ci95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = conf_int_mean(tmp, col1, col2, feat)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP')  \n",
    "    \n",
    "    ## 114. Std of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_prem_std'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).std()\n",
    "    tmp.columns=[feat]\n",
    "    tmp[feat]=tmp[feat].fillna(0)\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "\n",
    "    ## 115. 05 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct05'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.05)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    ## 116. 25 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct25'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.25)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    ## 117. 50 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct50'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.50)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    ## 118. 75 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct75'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.75)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    ## 119. 95 pct of Insured Premium\n",
    "    col1 = 'HH_and_Bld_Prem.'   ## what?\n",
    "    col2 = 'ZIP'        ## groupy municipality code\n",
    "    feat = 'build_prem_pct95'\n",
    "    tmp = insDataRed.filter([col1, col2], axis=1)\n",
    "    tmp = tmp.dropna()   ## remove nan values\n",
    "    tmp = tmp[tmp[col1]>0]\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp = tmp.groupby(by=[col2]).quantile(0.95)\n",
    "    tmp.columns=[feat]\n",
    "    dfFeat = pd.merge(dfFeat, tmp, on = 'ZIP') \n",
    "    \n",
    "    \n",
    "    for j in build_type_dic.values():\n",
    "        a='build_'+j+'_frac'\n",
    "        if a not in dfFeat.columns:\n",
    "            dfFeat[a]=0\n",
    "            \n",
    "    for j in [ 'MKL', 'KWA','VAN', 'OMK', 'UMK', 'MIC', 'CPE', 'SUV', 'LKL', 'CAB', 'ATV', 'SMA', 'ROL', 'CHO', 'GMA'] :\n",
    "        a='car1_'+j+'_frac'\n",
    "        if a not in dfFeat.columns:\n",
    "            dfFeat[a]=0\n",
    "            \n",
    "            \n",
    "    dfFeat.to_csv(\"../Data/aggregatedData/ZIP_%d.csv\"%years[i])\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2008,2020,1)\n",
    "def ageClass(df, age0, age1):\n",
    "    dfAge = df[df['age'] < age1]\n",
    "    dfAge = dfAge[dfAge['age'] >= age0]\n",
    "    dfAge = dfAge.groupby(['BFS']).count().reset_index()\n",
    "    df = df.groupby(['BFS']).count().reset_index()\n",
    "    df = df[['BFS', 'age']]\n",
    "    dfAge = dfAge[['BFS', 'age']]\n",
    "    dfAge.columns = ['BFS', 'ageClass']\n",
    "    df = pd.merge(df, dfAge, on = 'BFS')\n",
    "    df['percentage'] = 100*( df['ageClass'] / df['age'] )\n",
    "    df = df[['percentage', 'BFS']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(result):\n",
    "    df = pd.read_csv(path+j, error_bad_lines=False, encoding='iso-8859-1', sep=\";\")\n",
    "    ## Zip codes - commune codes (year specific)\n",
    "    zipBFS = pd.read_csv(\"../Data/ZIP_BFS_Historical_Mapping/\"+zip_bfs_folders_dict[years[i]]+\"/PLZO_CSV_WGS84.csv\",encoding='iso-8859-1', sep=zip_bfs_sep_dict[years[i]])\n",
    "    zipBFS.rename(columns={'PLZ':'ZIP', 'BFS-Nr':'BFS'}, inplace=True)\n",
    "    zipBFS = zipBFS[['ZIP', 'BFS']]\n",
    "    zipBFS = zipBFS.drop_duplicates(subset=['ZIP', 'BFS'], keep='first').reset_index(drop=True)\n",
    "    \n",
    "    df = pd.merge(df, zipBFS, on = 'ZIP')\n",
    "    df = df[['Nmbr', 'YearOfBirth', 'ZIP', 'BFS']]\n",
    "    df['age'] = years[i] - df['YearOfBirth']\n",
    "    df1 = ageClass(df, 0, 20)\n",
    "    df1.columns = ['Age 0-19', 'BFS']\n",
    "    df2 = ageClass(df, 20, 65)\n",
    "    df2.columns = ['Age 20-64', 'BFS']\n",
    "    df3 = ageClass(df, 65, 1000)\n",
    "    df3.columns = ['Age >64', 'BFS']\n",
    "    dfAge = pd.merge(df1, df2, on='BFS', how='outer')\n",
    "    dfAge = pd.merge(dfAge, df3, how='outer')\n",
    "    dfAge=dfAge.fillna(0)\n",
    "    dfAge = pd.merge(dfAge, unchanged_mun, on = 'BFS', how='right')\n",
    "    dfAge.to_csv(\"../Data/ageData/ages_%d.csv\"%years[i], index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
